//
// DO NOT EDIT.
// swift-format-ignore-file
//
// Generated by the protocol buffer compiler.
// Source: speechly/slu/v1/batch_api.proto
//
import GRPC
import NIO
import NIOConcurrencyHelpers
import SwiftProtobuf


/// Run SLU operations on audio sources without actively waiting the results.
///
/// Usage: instantiate `Speechly_Slu_V1_BatchAPIClient`, then call methods of this protocol to make API calls.
public protocol Speechly_Slu_V1_BatchAPIClientProtocol: GRPCClient {
  var serviceName: String { get }
  var interceptors: Speechly_Slu_V1_BatchAPIClientInterceptorFactoryProtocol? { get }

  func processAudio(
    callOptions: CallOptions?
  ) -> ClientStreamingCall<Speechly_Slu_V1_ProcessAudioRequest, Speechly_Slu_V1_ProcessAudioResponse>

  func queryStatus(
    _ request: Speechly_Slu_V1_QueryStatusRequest,
    callOptions: CallOptions?
  ) -> UnaryCall<Speechly_Slu_V1_QueryStatusRequest, Speechly_Slu_V1_QueryStatusResponse>
}

extension Speechly_Slu_V1_BatchAPIClientProtocol {
  public var serviceName: String {
    return "speechly.slu.v1.BatchAPI"
  }

  /// Create a new background SLU operation for a single audio source.
  /// An audio source can be
  ///  - audio chunks sent via repeated ProcessAudioRequests, or
  ///  - URI of a file, reachable from the API
  ///  The response includes an `id` that is used to match the operation to the
  ///  results. A `reference` identifier can also be set.
  ///  The destination can be a webhook URL, in which case the results are posted
  ///  there when they are ready. The payload is an instance of `Operation`.
  ///
  /// Callers should use the `send` method on the returned object to send messages
  /// to the server. The caller should send an `.end` after the final message has been sent.
  ///
  /// - Parameters:
  ///   - callOptions: Call options.
  /// - Returns: A `ClientStreamingCall` with futures for the metadata, status and response.
  public func processAudio(
    callOptions: CallOptions? = nil
  ) -> ClientStreamingCall<Speechly_Slu_V1_ProcessAudioRequest, Speechly_Slu_V1_ProcessAudioResponse> {
    return self.makeClientStreamingCall(
      path: Speechly_Slu_V1_BatchAPIClientMetadata.Methods.processAudio.path,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeProcessAudioInterceptors() ?? []
    )
  }

  /// Query the status of a given batch operation.
  /// If the `ProcessAudioRequest` did not define a `results_uri` as a
  /// destination, the results are returned in the `QueryStatusResponse`.
  ///
  /// - Parameters:
  ///   - request: Request to send to QueryStatus.
  ///   - callOptions: Call options.
  /// - Returns: A `UnaryCall` with futures for the metadata, status and response.
  public func queryStatus(
    _ request: Speechly_Slu_V1_QueryStatusRequest,
    callOptions: CallOptions? = nil
  ) -> UnaryCall<Speechly_Slu_V1_QueryStatusRequest, Speechly_Slu_V1_QueryStatusResponse> {
    return self.makeUnaryCall(
      path: Speechly_Slu_V1_BatchAPIClientMetadata.Methods.queryStatus.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeQueryStatusInterceptors() ?? []
    )
  }
}

@available(*, deprecated)
extension Speechly_Slu_V1_BatchAPIClient: @unchecked Sendable {}

@available(*, deprecated, renamed: "Speechly_Slu_V1_BatchAPINIOClient")
public final class Speechly_Slu_V1_BatchAPIClient: Speechly_Slu_V1_BatchAPIClientProtocol {
  private let lock = Lock()
  private var _defaultCallOptions: CallOptions
  private var _interceptors: Speechly_Slu_V1_BatchAPIClientInterceptorFactoryProtocol?
  public let channel: GRPCChannel
  public var defaultCallOptions: CallOptions {
    get { self.lock.withLock { return self._defaultCallOptions } }
    set { self.lock.withLockVoid { self._defaultCallOptions = newValue } }
  }
  public var interceptors: Speechly_Slu_V1_BatchAPIClientInterceptorFactoryProtocol? {
    get { self.lock.withLock { return self._interceptors } }
    set { self.lock.withLockVoid { self._interceptors = newValue } }
  }

  /// Creates a client for the speechly.slu.v1.BatchAPI service.
  ///
  /// - Parameters:
  ///   - channel: `GRPCChannel` to the service host.
  ///   - defaultCallOptions: Options to use for each service call if the user doesn't provide them.
  ///   - interceptors: A factory providing interceptors for each RPC.
  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Speechly_Slu_V1_BatchAPIClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self._defaultCallOptions = defaultCallOptions
    self._interceptors = interceptors
  }
}

public struct Speechly_Slu_V1_BatchAPINIOClient: Speechly_Slu_V1_BatchAPIClientProtocol {
  public var channel: GRPCChannel
  public var defaultCallOptions: CallOptions
  public var interceptors: Speechly_Slu_V1_BatchAPIClientInterceptorFactoryProtocol?

  /// Creates a client for the speechly.slu.v1.BatchAPI service.
  ///
  /// - Parameters:
  ///   - channel: `GRPCChannel` to the service host.
  ///   - defaultCallOptions: Options to use for each service call if the user doesn't provide them.
  ///   - interceptors: A factory providing interceptors for each RPC.
  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Speechly_Slu_V1_BatchAPIClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self.defaultCallOptions = defaultCallOptions
    self.interceptors = interceptors
  }
}

/// Run SLU operations on audio sources without actively waiting the results.
@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
public protocol Speechly_Slu_V1_BatchAPIAsyncClientProtocol: GRPCClient {
  static var serviceDescriptor: GRPCServiceDescriptor { get }
  var interceptors: Speechly_Slu_V1_BatchAPIClientInterceptorFactoryProtocol? { get }

  func makeProcessAudioCall(
    callOptions: CallOptions?
  ) -> GRPCAsyncClientStreamingCall<Speechly_Slu_V1_ProcessAudioRequest, Speechly_Slu_V1_ProcessAudioResponse>

  func makeQueryStatusCall(
    _ request: Speechly_Slu_V1_QueryStatusRequest,
    callOptions: CallOptions?
  ) -> GRPCAsyncUnaryCall<Speechly_Slu_V1_QueryStatusRequest, Speechly_Slu_V1_QueryStatusResponse>
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Speechly_Slu_V1_BatchAPIAsyncClientProtocol {
  public static var serviceDescriptor: GRPCServiceDescriptor {
    return Speechly_Slu_V1_BatchAPIClientMetadata.serviceDescriptor
  }

  public var interceptors: Speechly_Slu_V1_BatchAPIClientInterceptorFactoryProtocol? {
    return nil
  }

  public func makeProcessAudioCall(
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncClientStreamingCall<Speechly_Slu_V1_ProcessAudioRequest, Speechly_Slu_V1_ProcessAudioResponse> {
    return self.makeAsyncClientStreamingCall(
      path: Speechly_Slu_V1_BatchAPIClientMetadata.Methods.processAudio.path,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeProcessAudioInterceptors() ?? []
    )
  }

  public func makeQueryStatusCall(
    _ request: Speechly_Slu_V1_QueryStatusRequest,
    callOptions: CallOptions? = nil
  ) -> GRPCAsyncUnaryCall<Speechly_Slu_V1_QueryStatusRequest, Speechly_Slu_V1_QueryStatusResponse> {
    return self.makeAsyncUnaryCall(
      path: Speechly_Slu_V1_BatchAPIClientMetadata.Methods.queryStatus.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeQueryStatusInterceptors() ?? []
    )
  }
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Speechly_Slu_V1_BatchAPIAsyncClientProtocol {
  public func processAudio<RequestStream>(
    _ requests: RequestStream,
    callOptions: CallOptions? = nil
  ) async throws -> Speechly_Slu_V1_ProcessAudioResponse where RequestStream: Sequence, RequestStream.Element == Speechly_Slu_V1_ProcessAudioRequest {
    return try await self.performAsyncClientStreamingCall(
      path: Speechly_Slu_V1_BatchAPIClientMetadata.Methods.processAudio.path,
      requests: requests,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeProcessAudioInterceptors() ?? []
    )
  }

  public func processAudio<RequestStream>(
    _ requests: RequestStream,
    callOptions: CallOptions? = nil
  ) async throws -> Speechly_Slu_V1_ProcessAudioResponse where RequestStream: AsyncSequence & Sendable, RequestStream.Element == Speechly_Slu_V1_ProcessAudioRequest {
    return try await self.performAsyncClientStreamingCall(
      path: Speechly_Slu_V1_BatchAPIClientMetadata.Methods.processAudio.path,
      requests: requests,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeProcessAudioInterceptors() ?? []
    )
  }

  public func queryStatus(
    _ request: Speechly_Slu_V1_QueryStatusRequest,
    callOptions: CallOptions? = nil
  ) async throws -> Speechly_Slu_V1_QueryStatusResponse {
    return try await self.performAsyncUnaryCall(
      path: Speechly_Slu_V1_BatchAPIClientMetadata.Methods.queryStatus.path,
      request: request,
      callOptions: callOptions ?? self.defaultCallOptions,
      interceptors: self.interceptors?.makeQueryStatusInterceptors() ?? []
    )
  }
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
public struct Speechly_Slu_V1_BatchAPIAsyncClient: Speechly_Slu_V1_BatchAPIAsyncClientProtocol {
  public var channel: GRPCChannel
  public var defaultCallOptions: CallOptions
  public var interceptors: Speechly_Slu_V1_BatchAPIClientInterceptorFactoryProtocol?

  public init(
    channel: GRPCChannel,
    defaultCallOptions: CallOptions = CallOptions(),
    interceptors: Speechly_Slu_V1_BatchAPIClientInterceptorFactoryProtocol? = nil
  ) {
    self.channel = channel
    self.defaultCallOptions = defaultCallOptions
    self.interceptors = interceptors
  }
}

public protocol Speechly_Slu_V1_BatchAPIClientInterceptorFactoryProtocol: Sendable {

  /// - Returns: Interceptors to use when invoking 'processAudio'.
  func makeProcessAudioInterceptors() -> [ClientInterceptor<Speechly_Slu_V1_ProcessAudioRequest, Speechly_Slu_V1_ProcessAudioResponse>]

  /// - Returns: Interceptors to use when invoking 'queryStatus'.
  func makeQueryStatusInterceptors() -> [ClientInterceptor<Speechly_Slu_V1_QueryStatusRequest, Speechly_Slu_V1_QueryStatusResponse>]
}

public enum Speechly_Slu_V1_BatchAPIClientMetadata {
  public static let serviceDescriptor = GRPCServiceDescriptor(
    name: "BatchAPI",
    fullName: "speechly.slu.v1.BatchAPI",
    methods: [
      Speechly_Slu_V1_BatchAPIClientMetadata.Methods.processAudio,
      Speechly_Slu_V1_BatchAPIClientMetadata.Methods.queryStatus,
    ]
  )

  public enum Methods {
    public static let processAudio = GRPCMethodDescriptor(
      name: "ProcessAudio",
      path: "/speechly.slu.v1.BatchAPI/ProcessAudio",
      type: GRPCCallType.clientStreaming
    )

    public static let queryStatus = GRPCMethodDescriptor(
      name: "QueryStatus",
      path: "/speechly.slu.v1.BatchAPI/QueryStatus",
      type: GRPCCallType.unary
    )
  }
}

/// Run SLU operations on audio sources without actively waiting the results.
///
/// To build a server, implement a class that conforms to this protocol.
public protocol Speechly_Slu_V1_BatchAPIProvider: CallHandlerProvider {
  var interceptors: Speechly_Slu_V1_BatchAPIServerInterceptorFactoryProtocol? { get }

  /// Create a new background SLU operation for a single audio source.
  /// An audio source can be
  ///  - audio chunks sent via repeated ProcessAudioRequests, or
  ///  - URI of a file, reachable from the API
  ///  The response includes an `id` that is used to match the operation to the
  ///  results. A `reference` identifier can also be set.
  ///  The destination can be a webhook URL, in which case the results are posted
  ///  there when they are ready. The payload is an instance of `Operation`.
  func processAudio(context: UnaryResponseCallContext<Speechly_Slu_V1_ProcessAudioResponse>) -> EventLoopFuture<(StreamEvent<Speechly_Slu_V1_ProcessAudioRequest>) -> Void>

  /// Query the status of a given batch operation.
  /// If the `ProcessAudioRequest` did not define a `results_uri` as a
  /// destination, the results are returned in the `QueryStatusResponse`.
  func queryStatus(request: Speechly_Slu_V1_QueryStatusRequest, context: StatusOnlyCallContext) -> EventLoopFuture<Speechly_Slu_V1_QueryStatusResponse>
}

extension Speechly_Slu_V1_BatchAPIProvider {
  public var serviceName: Substring {
    return Speechly_Slu_V1_BatchAPIServerMetadata.serviceDescriptor.fullName[...]
  }

  /// Determines, calls and returns the appropriate request handler, depending on the request's method.
  /// Returns nil for methods not handled by this service.
  public func handle(
    method name: Substring,
    context: CallHandlerContext
  ) -> GRPCServerHandlerProtocol? {
    switch name {
    case "ProcessAudio":
      return ClientStreamingServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Speechly_Slu_V1_ProcessAudioRequest>(),
        responseSerializer: ProtobufSerializer<Speechly_Slu_V1_ProcessAudioResponse>(),
        interceptors: self.interceptors?.makeProcessAudioInterceptors() ?? [],
        observerFactory: self.processAudio(context:)
      )

    case "QueryStatus":
      return UnaryServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Speechly_Slu_V1_QueryStatusRequest>(),
        responseSerializer: ProtobufSerializer<Speechly_Slu_V1_QueryStatusResponse>(),
        interceptors: self.interceptors?.makeQueryStatusInterceptors() ?? [],
        userFunction: self.queryStatus(request:context:)
      )

    default:
      return nil
    }
  }
}

/// Run SLU operations on audio sources without actively waiting the results.
///
/// To implement a server, implement an object which conforms to this protocol.
@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
public protocol Speechly_Slu_V1_BatchAPIAsyncProvider: CallHandlerProvider, Sendable {
  static var serviceDescriptor: GRPCServiceDescriptor { get }
  var interceptors: Speechly_Slu_V1_BatchAPIServerInterceptorFactoryProtocol? { get }

  /// Create a new background SLU operation for a single audio source.
  /// An audio source can be
  ///  - audio chunks sent via repeated ProcessAudioRequests, or
  ///  - URI of a file, reachable from the API
  ///  The response includes an `id` that is used to match the operation to the
  ///  results. A `reference` identifier can also be set.
  ///  The destination can be a webhook URL, in which case the results are posted
  ///  there when they are ready. The payload is an instance of `Operation`.
  func processAudio(
    requestStream: GRPCAsyncRequestStream<Speechly_Slu_V1_ProcessAudioRequest>,
    context: GRPCAsyncServerCallContext
  ) async throws -> Speechly_Slu_V1_ProcessAudioResponse

  /// Query the status of a given batch operation.
  /// If the `ProcessAudioRequest` did not define a `results_uri` as a
  /// destination, the results are returned in the `QueryStatusResponse`.
  func queryStatus(
    request: Speechly_Slu_V1_QueryStatusRequest,
    context: GRPCAsyncServerCallContext
  ) async throws -> Speechly_Slu_V1_QueryStatusResponse
}

@available(macOS 10.15, iOS 13, tvOS 13, watchOS 6, *)
extension Speechly_Slu_V1_BatchAPIAsyncProvider {
  public static var serviceDescriptor: GRPCServiceDescriptor {
    return Speechly_Slu_V1_BatchAPIServerMetadata.serviceDescriptor
  }

  public var serviceName: Substring {
    return Speechly_Slu_V1_BatchAPIServerMetadata.serviceDescriptor.fullName[...]
  }

  public var interceptors: Speechly_Slu_V1_BatchAPIServerInterceptorFactoryProtocol? {
    return nil
  }

  public func handle(
    method name: Substring,
    context: CallHandlerContext
  ) -> GRPCServerHandlerProtocol? {
    switch name {
    case "ProcessAudio":
      return GRPCAsyncServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Speechly_Slu_V1_ProcessAudioRequest>(),
        responseSerializer: ProtobufSerializer<Speechly_Slu_V1_ProcessAudioResponse>(),
        interceptors: self.interceptors?.makeProcessAudioInterceptors() ?? [],
        wrapping: { try await self.processAudio(requestStream: $0, context: $1) }
      )

    case "QueryStatus":
      return GRPCAsyncServerHandler(
        context: context,
        requestDeserializer: ProtobufDeserializer<Speechly_Slu_V1_QueryStatusRequest>(),
        responseSerializer: ProtobufSerializer<Speechly_Slu_V1_QueryStatusResponse>(),
        interceptors: self.interceptors?.makeQueryStatusInterceptors() ?? [],
        wrapping: { try await self.queryStatus(request: $0, context: $1) }
      )

    default:
      return nil
    }
  }
}

public protocol Speechly_Slu_V1_BatchAPIServerInterceptorFactoryProtocol: Sendable {

  /// - Returns: Interceptors to use when handling 'processAudio'.
  ///   Defaults to calling `self.makeInterceptors()`.
  func makeProcessAudioInterceptors() -> [ServerInterceptor<Speechly_Slu_V1_ProcessAudioRequest, Speechly_Slu_V1_ProcessAudioResponse>]

  /// - Returns: Interceptors to use when handling 'queryStatus'.
  ///   Defaults to calling `self.makeInterceptors()`.
  func makeQueryStatusInterceptors() -> [ServerInterceptor<Speechly_Slu_V1_QueryStatusRequest, Speechly_Slu_V1_QueryStatusResponse>]
}

public enum Speechly_Slu_V1_BatchAPIServerMetadata {
  public static let serviceDescriptor = GRPCServiceDescriptor(
    name: "BatchAPI",
    fullName: "speechly.slu.v1.BatchAPI",
    methods: [
      Speechly_Slu_V1_BatchAPIServerMetadata.Methods.processAudio,
      Speechly_Slu_V1_BatchAPIServerMetadata.Methods.queryStatus,
    ]
  )

  public enum Methods {
    public static let processAudio = GRPCMethodDescriptor(
      name: "ProcessAudio",
      path: "/speechly.slu.v1.BatchAPI/ProcessAudio",
      type: GRPCCallType.clientStreaming
    )

    public static let queryStatus = GRPCMethodDescriptor(
      name: "QueryStatus",
      path: "/speechly.slu.v1.BatchAPI/QueryStatus",
      type: GRPCCallType.unary
    )
  }
}
